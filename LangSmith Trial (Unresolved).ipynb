{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable # Auto-trace this function\n",
    "def pipeline(user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "pipeline(\"Hello, world!\")\n",
    "# Out:  Hello there! How can I assist you today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithUserError",
     "evalue": "API key must be provided when using hosted LangSmith API",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangSmithUserError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexact_match\u001b[39m(run, example):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: run\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m example\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m---> 25\u001b[0m experiment_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWelcome \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpostfix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Your AI system goes here\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The data to predict and grade over\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mexact_match\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The evaluators to score the results\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample-experiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The name of the experiment\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrevision_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/GenAI/kai (CGU's AI Assistant)/CGUs-AI-Assistant/venv/lib/python3.10/site-packages/langsmith/evaluation/_runner.py:224\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, max_concurrency, client, blocking)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[1;32m     73\u001b[0m     target: TARGET_T,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExperimentResults:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate a target system or function on a given dataset.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m        View the evaluation results for experiment:...\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/GenAI/kai (CGU's AI Assistant)/CGUs-AI-Assistant/venv/lib/python3.10/site-packages/langsmith/evaluation/_runner.py:422\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, max_concurrency, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\n\u001b[1;32m    409\u001b[0m     target: Union[TARGET_T, Iterable[schemas\u001b[38;5;241m.\u001b[39mRun]],\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExperimentResults:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Initialize the experiment manager.\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     client \u001b[38;5;241m=\u001b[39m client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlangsmith\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas\u001b[38;5;241m.\u001b[39mRun], target)\n\u001b[1;32m    424\u001b[0m     experiment_, runs \u001b[38;5;241m=\u001b[39m _resolve_experiment(\n\u001b[1;32m    425\u001b[0m         experiment,\n\u001b[1;32m    426\u001b[0m         runs,\n\u001b[1;32m    427\u001b[0m         client,\n\u001b[1;32m    428\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/GenAI/kai (CGU's AI Assistant)/CGUs-AI-Assistant/venv/lib/python3.10/site-packages/langsmith/client.py:533\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, api_url, api_key, retry_config, timeout_ms, web_url, session, auto_batch_tracing, hide_inputs, hide_outputs, info, api_urls)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url \u001b[38;5;241m=\u001b[39m _get_api_url(api_url)\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m _get_api_key(api_key)\n\u001b[0;32m--> 533\u001b[0m     \u001b[43m_validate_api_key_if_hosted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_api_urls \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key}\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_config \u001b[38;5;241m=\u001b[39m retry_config \u001b[38;5;129;01mor\u001b[39;00m _default_retry_config()\n",
      "File \u001b[0;32m~/Downloads/GenAI/kai (CGU's AI Assistant)/CGUs-AI-Assistant/venv/lib/python3.10/site-packages/langsmith/client.py:322\u001b[0m, in \u001b[0;36m_validate_api_key_if_hosted\u001b[0;34m(api_url, api_key)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_langchain_hosted(api_url):\n\u001b[0;32m--> 322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithUserError(\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI key must be provided when using hosted LangSmith API\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    324\u001b[0m         )\n",
      "\u001b[0;31mLangSmithUserError\u001b[0m: API key must be provided when using hosted LangSmith API"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "client = Client(api_key= 'ls__1b6be84ebec14bbb9762fb40ab1fd083')\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"Sample Dataset\"\n",
    "dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"postfix\": \"to LangSmith\"},\n",
    "        {\"postfix\": \"to Evaluations in LangSmith\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"output\": \"Welcome to LangSmith\"},\n",
    "        {\"output\": \"Welcome to Evaluations in LangSmith\"},\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "# Define your evaluator\n",
    "def exact_match(run, example):\n",
    "    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    lambda input: \"Welcome \" + input['postfix'], # Your AI system goes here\n",
    "    data=dataset_name, # The data to predict and grade over\n",
    "    evaluators=[exact_match], # The evaluators to score the results\n",
    "    experiment_prefix=\"sample-experiment\", # The name of the experiment\n",
    "    metadata={\n",
    "      \"version\": \"1.0.0\",\n",
    "      \"revision_id\": \"beta\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"finance\", \"housing\", \"admission\"]\n",
    "prompt = ClassificationPrompt(\n",
    "    introduction=\"Please categorize the following text about CGU:\",\n",
    "    categories=categories,\n",
    "    examples=[(\"What are the tuition fees?\", \"finance\"),\n",
    "              (\"Are there dorms available?\", \"housing\"),\n",
    "              (\"What is the admission process?\", \"admission\")]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cguai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
